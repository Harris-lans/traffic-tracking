{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2\n",
    "\n",
    "## Overview\n",
    "\n",
    "The solution to the 2nd task of Exercise 1 focuses on counting the number of cars travelling towards the `City Centre` in each of the provided videos using similar frame differencing techniques used in the 1st task of this exercise. This notebook implements the solution and explains the step-by-step implementation process. The theoretical aspects of these techniques will be further elaborated in the report submitted alongside this notebook.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count cars heading towards City Centre  \n",
    "\n",
    "To begin, we first setup an array to hold the paths of the videos in which the cars should be counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = ['videos/Traffic_Laramie_1.mp4', 'videos/Traffic_Laramie_2.mp4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using very similar logic to the first task but with some additions to process. Since we have two videos, we'll move the logic to function to make it reusable. \n",
    "\n",
    "The below function will count the number of cars passing in a direction within the detection bounding box and it will follow the following steps:\n",
    "\n",
    "1. **Loading Video**: To begin, we first load the video using the `load_video_file` function from the `cv_utils.py` file, which internally uses the python opencv library. \n",
    "\n",
    "2. **Calculate Background Frame**: The background frame is obtained by calculating the median frame from a sample of 200 random frames the video. This is done by the `get_median_frame` in the `cv_utils.py` file.\n",
    "\n",
    "3. **Reading Frames**: Then each frame of the video is read until the end or until the 'q' key is pressed.\n",
    "\n",
    "4. **Grayscale Conversion**: A grayscale version of the current frame is created using the `cv2.cvtColor()` function. Grayscale images simplify the analysis by removing color information.\n",
    "\n",
    "5. **Background Subtraction**: The background frame is subtracted from the current grayscale frame to isolate moving objects using the `subtract_background()` function from `cv_utils`.\n",
    "\n",
    "6. **Preprocessing the Subtracted Frame**: The subtracted frame is preprocessed to enhance the moving objects:\n",
    "   * **Thresholding**: A threshold is applied to the foreground mask to highlight moving objects.\n",
    "   * **Dilation**: The shapes in the foreground mask are dilated to fill out black regions within the shapes.\n",
    "   * **Erosion**: The boundary of the shapes in the foreground mask is eroded to smoothen out the edges of moving objects.\n",
    "\n",
    "7. **Car Identification**: Bounding boxes of cars are detected using the `cv2.findContours()` function on the preprocessed foreground mask. The cars are identified by comparing the bounding box centroids of current frame with the bounding box centroids of the previous frame and match them if the distance between them in the consecutive frames is within a threshold.\n",
    "\n",
    "8. **Counting Cars**: The cars that are within the detection area and are heading in the specified direction are counted. Each uniquely identified car is counted only once.\n",
    "\n",
    "9. **Drawing Bounding Boxes and Counter**: This part is executed only if the `render_window` parameter for the function is `True`. The bounding boxes for the area of detection and cars and the car counter are drawn to a copy of the original frame.\n",
    "\n",
    "10. **Rendering and Playback**: Similar to the previous step, this step is only executed if the `render_window` parameter for the function is `True`. The modified frame with the bounding boxes and the counter is rendered in a window. The frames are updated based on the frame time of the video to maintain proper playback.\n",
    "\n",
    "11. **Return Cars Count and Cars Passing per Minute**: Calculate cars count and cars per minute and returning the values as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector import Vector\n",
    "from rect import Rect\n",
    "import cv_utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from car import Car\n",
    "from vector_moving_average_filter import VectorMovingAverageFilter\n",
    "\n",
    "def count_cars_in_video_heading_in_direction(video_path: str, \n",
    "                                             direction: Vector, \n",
    "                                             area_of_detection_bounding_box: Rect, \n",
    "                                             min_car_bounding_box_area: int,\n",
    "                                             car_tracking_identity_distance_threshold: int=80,\n",
    "                                             car_direction_angle_threshold: int=20,\n",
    "                                             render_window: bool=True):\n",
    "    # Loading video\n",
    "    video, video_metadata = cv_utils.load_video_file(video_path)\n",
    "    # Extracting background frame\n",
    "    background_frame = cv_utils.get_median_frame(video_path, 200)\n",
    "    background_gray_frame = cv2.cvtColor(background_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    frame_time_ms = int(round(1000 / video_metadata[\"frame_rate\"]))\n",
    "    \n",
    "    # Setting up variables for tracking cars\n",
    "    tracked_cars = {}\n",
    "    tracked_cars_moving_average_filters = {}\n",
    "    tracked_cars_absent_frame_counts = {}\n",
    "    car_id_counter = 0\n",
    "    counted_car_ids = []\n",
    "    cars_count = 0\n",
    "    \n",
    "    # Read until video is completed or we press 'q'\n",
    "    while True:\n",
    "        # Reading frame\n",
    "        check, frame = video.read()\n",
    "\n",
    "        if check == True:\n",
    "            # Creating grayscale version of frame\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Subtracting background frame from current frame\n",
    "            foreground_frame = cv_utils.subtract_background(background_gray_frame, gray_frame)\n",
    "\n",
    "            ## Preprocess subtracted frame\n",
    "            # Thresholding the foreground_mask to highlight the moving objects\n",
    "            _, foreground_mask = cv2.threshold(foreground_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "            # Dilate the shapes in the foreground mask to fill out black regions within the shape\n",
    "            foreground_mask = cv2.dilate(foreground_mask, np.ones((9, 9), np.uint8), iterations=2)\n",
    "            # Erode the boundary of the shapes in the foreground mask to smoothen out the edges of the moving objects\n",
    "            foreground_mask = cv2.erode(foreground_mask, np.ones((5, 5), np.uint8), iterations=1)\n",
    "\n",
    "            # Detect bounding boxes of cars from foreground_mask using contours method from opencv\n",
    "            car_bounding_boxes = []\n",
    "            contours, _ = cv2.findContours(foreground_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for contour in contours:\n",
    "                # Accessing the x, y and height, width of the cars\n",
    "                x, y, width, height = cv2.boundingRect(contour)\n",
    "                contourBoundingRect = Rect(Vector(x, y), width, height)\n",
    "\n",
    "                if cv2.contourArea(contour) > min_car_bounding_box_area and Rect.is_rect_within_rect(area_of_detection_bounding_box, contourBoundingRect):\n",
    "                    # Recording bounding boxes of the cars\n",
    "                    car_bounding_boxes.append(contourBoundingRect)\n",
    "\n",
    "            # Loop through the detected boxes and associating them with existing cars based on new positions or create new ones\n",
    "            unmatched_tracked_car_ids = set(tracked_cars.keys())\n",
    "            for car_bounding_box in car_bounding_boxes:\n",
    "                centroid = car_bounding_box.get_centroid()\n",
    "                matched_car_id = None\n",
    "                for car_id, car in tracked_cars.items():\n",
    "                    distance = Vector.distance(centroid, car.position)\n",
    "                    if distance < car_tracking_identity_distance_threshold:\n",
    "                        matched_car_id = car_id\n",
    "                        break\n",
    "\n",
    "                if matched_car_id is None:\n",
    "                    # Create a new car ID\n",
    "                    car_id = car_id_counter\n",
    "                    car_id_counter += 1\n",
    "                    tracked_cars_moving_average_filters[car_id] = VectorMovingAverageFilter(10)\n",
    "                    smoothed_centroid = tracked_cars_moving_average_filters[car_id].smoothen_value(centroid)\n",
    "                    tracked_cars[car_id] = Car(smoothed_centroid, Vector(0, 0))\n",
    "                else:\n",
    "                    # Smoothening centroid using corresponding moving average filter \n",
    "                    smoothed_centroid = tracked_cars_moving_average_filters[matched_car_id].smoothen_value(centroid)\n",
    "                    # Updating the matched car with new position if the new position is different\n",
    "                    tracked_cars[matched_car_id].direction = smoothed_centroid - tracked_cars[matched_car_id].position\n",
    "                    tracked_cars[matched_car_id].position = smoothed_centroid\n",
    "                    # Removing matched id from set of unmatched car ids\n",
    "                    unmatched_tracked_car_ids.remove(matched_car_id)\n",
    "\n",
    "            # Check if cars are no longer available and remove them from tracked_cars dictionary\n",
    "            for car_id in unmatched_tracked_car_ids:\n",
    "                # Car not detected in current frame, increment absent frame count\n",
    "                tracked_cars_absent_frame_counts[car_id] = tracked_cars_absent_frame_counts.get(car_id, 0) + 1\n",
    "\n",
    "                # Check if car has been absent for too many frames\n",
    "                if tracked_cars_absent_frame_counts[car_id] > 10:\n",
    "                    # Remove car from tracked_cars and absent_frame_counts dictionaries\n",
    "                    del tracked_cars[car_id]\n",
    "                    del tracked_cars_moving_average_filters[car_id]\n",
    "                    del tracked_cars_absent_frame_counts[car_id]\n",
    "\n",
    "            # Checking if any new cars are heading from downtown to city centre and counting them\n",
    "            for car_id, car in tracked_cars.items():\n",
    "                if car_id not in counted_car_ids:\n",
    "                    # Checking if the car is heading in the general direction of the city centre\n",
    "                    if not car.direction.is_zero() and Vector.angle_between(car.direction, direction) <= car_direction_angle_threshold:\n",
    "                        cars_count += 1\n",
    "                        counted_car_ids.append(car_id)\n",
    "            \n",
    "            if render_window:\n",
    "                # Draw bounding box for area of detection\n",
    "                cv_utils.draw_rect_in_frame(frame, area_of_detection_bounding_box, (0, 0, 255))\n",
    "                # Drawing bounding box for all the cars\n",
    "                for car_bounding_box in car_bounding_boxes:\n",
    "                    cv_utils.draw_rect_in_frame(frame, car_bounding_box, (0, 255, 0))\n",
    "                # Draw count of cars heading to city centre\n",
    "                cv_utils.draw_text_in_frame(frame, \n",
    "                                            f\"Cars Headed to City Centre: {cars_count}\",\n",
    "                                            Vector(30, 60),\n",
    "                                            (0, 255, 0),\n",
    "                                            font_scale=0.7)\n",
    "            \n",
    "                cv2.imshow(\"movie\", frame)\n",
    "                \n",
    "                if cv2.waitKey(frame_time_ms) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "            else:\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release the video object\n",
    "    video.release()\n",
    "    \n",
    "    # Destroy all the windows if rendered\n",
    "    if render_window:\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Waiting for the windows to close properly\n",
    "        cv2.waitKey(10)\n",
    "        \n",
    "    cars_per_minute = cars_count / (video_metadata['duration_secs']/60)\n",
    "    \n",
    "    return cars_count, cars_per_minute\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function for counting the cars heading in a direction ready, we can now prepare the parameters we will be using as arguments when calling the function. The below code snippet intializes the area of detection, which in this case is just junction in the footage, the minimum car bounding box area threshold and the direction to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating detection bounding box\n",
    "area_of_detection_bounding_box = Rect(\n",
    "    position=Vector(650, 320),\n",
    "    width=330,\n",
    "    height=278\n",
    ")\n",
    "\n",
    "# Defining minimum size of the calculated bounding boxes to be considered a car\n",
    "min_car_bounding_box_area = 4000\n",
    "\n",
    "# Defining direction to track\n",
    "direction_to_track = Vector(-1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the initialization variables created above to count cars in both videos provided and display the results as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>total_cars</th>\n",
       "      <th>cars_per_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>videos/Traffic_Laramie_1.mp4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.022472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>videos/Traffic_Laramie_2.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.264151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file_name  total_cars  cars_per_minute\n",
       "0  videos/Traffic_Laramie_1.mp4           6         2.022472\n",
       "1  videos/Traffic_Laramie_2.mp4           4         2.264151"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_counts = pd.DataFrame()\n",
    "\n",
    "for video_path in video_paths:\n",
    "    cars_count, cars_per_minute = count_cars_in_video_heading_in_direction(video_path,\n",
    "                                                                           direction_to_track,\n",
    "                                                                           area_of_detection_bounding_box, \n",
    "                                                                           min_car_bounding_box_area,\n",
    "                                                                           render_window=True)\n",
    "    new_row = {\n",
    "        'file_name': video_path, \n",
    "        'total_cars': cars_count, \n",
    "        'cars_per_minute': cars_per_minute\n",
    "    }\n",
    "    car_counts = pd.concat([car_counts, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "car_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
