{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.1 \n",
    "\n",
    "## Overview\n",
    "\n",
    "The solution to the 1st task of Exercise 1 focuses on detecting cars in the provided video and drawing bounding boxes around them using frame differencing and background subtraction. This notebook only implements the solution and discusses the step-by-step implementation process. The theoretical aspects of these techniques will be further elaborated in the report submitted alongside this notebook.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy in /Users/harish/opt/anaconda3/lib/python3.9/site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting moving cars\n",
    "\n",
    "To begin with we will create a function to track the cars passing within the detection bounding box. The function logic follows these steps:\n",
    "\n",
    "1. **Loading Video**: To begin, we first load the video using the `load_video_file()` function from the `cv_utils.py` file, which internally uses the python opencv library. \n",
    "\n",
    "2. **Calculate Background Frame**: We then extract the background frame by calculating the median frame from a sample of 200 random frames from the video. This is done by the `get_median_frame` in the `cv_utils.py` file.\n",
    "\n",
    "3. **Reading Frames**: Then each frame of the video is read until the end or until the 'q' key is pressed.\n",
    "\n",
    "4. **Grayscale Conversion**: A grayscale version of the current frame is created using the `cv2.cvtColor()` function. Grayscale images simplify the analysis by removing color information.\n",
    "\n",
    "5. **Background Subtraction**: The background frame is subtracted from the current grayscale frame to isolate moving objects using the `subtract_background()` function from `cv_utils`.\n",
    "\n",
    "6. **Preprocessing the Subtracted Frame**: The subtracted frame is preprocessed to enhance the moving objects:\n",
    "   * **Thresholding**: A threshold is applied to the foreground mask to highlight moving objects.\n",
    "   * **Dilation**: The shapes in the foreground mask are dilated to fill out black regions within the shapes.\n",
    "   * **Erosion**: The boundary of the shapes in the foreground mask is eroded to smoothen out the edges of moving objects.\n",
    "\n",
    "7. **Car Detection**: Bounding boxes of cars are detected using the `cv2.findContours()` function on the preprocessed foreground mask. Bounding boxes of cars that meet specific criteria are recorded.\n",
    "\n",
    "8. **Drawing Bounding Boxes**: The detected bounding boxes are drawn on a copy of the original video frame, where the area of detection is highlighted with a red bounding box and the bounding boxes around detected cars are drawn in green.\n",
    "\n",
    "9. **Rendering and Playback**: The modified frame with the bounding boxes is rendered in a window. The frames are updated based on the frame time of the video to maintain proper playback. If the `render_intermediate_frames` argument is set to `True`, the intermediate frames will be rendered in a separate window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv_utils\n",
    "import numpy as np\n",
    "from rect import Rect\n",
    "from vector import Vector\n",
    "\n",
    "def track_cars_in_video(video_path: str,  \n",
    "                        area_of_detection_bounding_box: Rect, \n",
    "                        min_car_bounding_box_area: int,\n",
    "                        render_intermediate_frames: bool=False):\n",
    "    # Loading video\n",
    "    video, video_metadata = cv_utils.load_video_file(video_path)\n",
    "    # Extracting background frame\n",
    "    background_frame = cv_utils.get_median_frame(video_path, 200)\n",
    "    background_gray_frame = cv2.cvtColor(background_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    frame_time_ms = int(round(1000 / video_metadata[\"frame_rate\"]))\n",
    "    \n",
    "    # Read until video is completed or we press 'q'\n",
    "    while True:\n",
    "        # Reading frame\n",
    "        check, frame = video.read()\n",
    "\n",
    "        if check == True:\n",
    "            # Creating frame copy\n",
    "            org_frame_copy = frame.copy()\n",
    "\n",
    "            # Creating grayscale version of frame\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Subtracting background frame from current frame\n",
    "            foreground_frame = cv_utils.subtract_background(background_gray_frame, gray_frame)\n",
    "\n",
    "            ## Preprocess subtracted frame\n",
    "            # Thresholding the foreground_mask to highlight the moving objects\n",
    "            _, foreground_mask_1 = cv2.threshold(foreground_frame, 25, 255, cv2.THRESH_BINARY)\n",
    "            # Dilate the shapes in the foreground mask to fill out black regions within the shape\n",
    "            foreground_mask_2 = cv2.dilate(foreground_mask_1, np.ones((9, 9), np.uint8), iterations = 2)\n",
    "            # Erode the boundary of the shapes in the foreground mask to smoothen out the edges of the moving objects\n",
    "            foreground_mask_3 = cv2.erode(foreground_mask_2, np.ones((5, 5), np.uint8), iterations = 1)\n",
    "\n",
    "            # Detect bounding boxes of cars from foreground_mask using contours method from opencv\n",
    "            car_bounding_boxes = []\n",
    "            contours, _ = cv2.findContours(foreground_mask_3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for contour in contours:\n",
    "                # Accessing the x, y and height, width of the cars\n",
    "                x, y, width, height = cv2.boundingRect(contour)\n",
    "                contourBoundingRect = Rect(Vector(x, y), width, height)\n",
    "\n",
    "                if cv2.contourArea(contour) > min_car_bounding_box_area and Rect.is_rect_within_rect(area_of_detection_bounding_box, contourBoundingRect, percentage_threshold=80):\n",
    "                    # Recording bounding boxes of the cars if 80% of the car's bounding box is within the area of detection\n",
    "                    car_bounding_boxes.append(contourBoundingRect)\n",
    "\n",
    "            # Draw bounding box for area of detection\n",
    "            cv_utils.draw_rect_in_frame(org_frame_copy, area_of_detection_bounding_box, (0, 0, 255))\n",
    "            # Drawing bounding box for all the cars\n",
    "            for car_bounding_box in car_bounding_boxes:\n",
    "                cv_utils.draw_rect_in_frame(org_frame_copy, car_bounding_box, (0, 255, 0))\n",
    "                \n",
    "            # Rendering the frame with bounding boxes to the window\n",
    "            cv2.imshow(\"tracking\", org_frame_copy)\n",
    "\n",
    "            if render_intermediate_frames:\n",
    "                # Stacking pre-processing frames\n",
    "                stacked_frame = np.vstack((\n",
    "                    np.hstack((frame, cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR), cv2.cvtColor(foreground_frame, cv2.COLOR_GRAY2BGR))),\n",
    "                    np.hstack((cv2.cvtColor(foreground_mask_1, cv2.COLOR_GRAY2BGR), cv2.cvtColor(foreground_mask_2, cv2.COLOR_GRAY2BGR), cv2.cvtColor(foreground_mask_3, cv2.COLOR_GRAY2BGR))),\n",
    "                ))\n",
    "\n",
    "                # Rendering the intermediate frames to the window\n",
    "                cv2.imshow(\"intermediate-frames\", stacked_frame)\n",
    "\n",
    "            # Sleeping for a time equal to the frame time of the video to maintain proper playback of video\n",
    "            if cv2.waitKey(frame_time_ms) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release the video object\n",
    "    video.release()\n",
    "\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Waiting for the windows to close properly\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function to track cars created, we need to declare the dimensions and position of the bounding box, within which the detection should work. As instructed in the task sheet, we only focus on cars moving in `Main Street`. The information is stored as an object the `Rect` class which represents a rectangle in 2D space with utility functions that help with certain calculations. Then, we also define the minimum area of a bounding box for it to be considered a car which will help in differentiating other moving objects from moving cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining detection bounding box\n",
    "area_of_detection_bounding_box = Rect(\n",
    "    position=Vector(1, 300),\n",
    "    width= 1037,\n",
    "    height= 298\n",
    ")\n",
    "\n",
    "# Declaring minimum area of the calculated bounding boxes to be considered a car\n",
    "min_car_bounding_box_area = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the created function and intialized variables to track cars in the provided video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_cars_in_video('videos/Traffic_Laramie_1.mp4',\n",
    "                    area_of_detection_bounding_box,\n",
    "                    min_car_bounding_box_area,\n",
    "                    render_intermediate_frames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
